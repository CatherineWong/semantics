{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Data Exploration\n",
    "Author: catwong@ 12/27/2018\n",
    "\n",
    "Env: Python 2 (no virtualenv)\n",
    "Datasets:\n",
    "- Regex, Learning with Latent Language (Andreas et. al) [https://github.com/jacobandreas/l3/tree/master/data]\n",
    "- Spatial Navigation (Janner et. al)\n",
    "[https://github.com/JannerM/spatial-reasoning]\n",
    "- CLEVR-Humans (Johnson et. al) [https://cs.stanford.edu/people/jcjohns/iep/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preliminary.exploration_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "# #train_hint = ngram_dataset_freq(l3_regex['train'], 'hint', n=1, verbose=True)\n",
    "# local_sr_fdist = ngram_dataset_freq(local_sr['train'], 'hints_aug', verbose=True)\n",
    "# clevr_fdist = ngram_dataset_freq(clevr_humans['train'], 'tokenized', verbose=False)\n",
    "\n",
    "# _ = ngram_cross_dataset_freq([local_sr_fdist, clevr_fdist], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data.dataset_loading import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L3-Regex\n",
    "\n",
    "l3_regex: dict with keys {train, test, val}; each list of dicts with keys:\n",
    "- examples: actual I/O pairs.\n",
    "- hint: the actual NLP examples.\n",
    "- hints_aug: templated, augmented.\n",
    "- re: the regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l3_regex: \n",
      "train: 3000 tasks\n",
      "val: 500 tasks\n",
      "test: 500 tasks\n"
     ]
    }
   ],
   "source": [
    "l3_regex=load_l3(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic summary: \n",
      "train: 3000 tasks\n",
      "val: 500 tasks\n",
      "test: 500 tasks\n"
     ]
    }
   ],
   "source": [
    "# Frequency Distributions\n",
    "\n",
    "train_hint = ngram_dataset_freq(l3_regex['train'], 'hints_aug', verbose=True)\n",
    "test_hint = ngram_dataset_freq(l3_regex['test'], 'hints_aug', verbose=True)\n",
    "\n",
    "train_hint = ngram_dataset_freq(l3_regex['train'], 'hints_aug', n=2, verbose=True)\n",
    "test_hint = ngram_dataset_freq(l3_regex['test'], 'hints_aug', n=2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Spatial Reasoning - Janner Version\n",
    "\n",
    "To load up to max_train train maps and max_val val maps with mode = [ local | global ] instructions and annotations = [ human | synthetic ] descriptions, run:\n",
    "\n",
    "~~~~\n",
    ">>> import data\n",
    ">>> train_data, val_data = data.load(mode, annotations, max_train, max_val)\n",
    ">>> layouts, objects, rewards, terminal, instructions, values, goals = train_data\n",
    "~~~~\n",
    "Local: 1566 train, 399 test\n",
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Data> Loading local train environments with human annotations\n",
      "<Data> Found 1566 annotations\n",
      "\n",
      "<Data> Loading local test environments with human annotations\n",
      "<Data> Found 399 annotations\n",
      "\n",
      "<Data> Loading global train environments with human annotations\n",
      "<Data> Found 1071 annotations\n",
      "\n",
      "<Data> Loading global test environments with human annotations\n",
      "<Data> Found 272 annotations\n",
      "Found 1566 train instructions.\n",
      "Found 399 test instructions.\n",
      "Found 1071 train instructions.\n",
      "Found 272 test instructions.\n"
     ]
    }
   ],
   "source": [
    "local_sr, global_sr = load_sr(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"LOCAL:\")\n",
    "_= ngram_dataset_freq(local_sr['train'], 'hints_aug', verbose=True)\n",
    "_= ngram_dataset_freq(local_sr['test'], 'hints_aug', verbose=True)\n",
    "\n",
    "_= ngram_dataset_freq(local_sr['train'], 'hints_aug', n=2, verbose=True)\n",
    "_= ngram_dataset_freq(local_sr['test'], 'hints_aug', n=2, verbose=True)\n",
    "\n",
    "print (\"\\nGLOBAL:\")\n",
    "_= ngram_dataset_freq(global_sr['train'], 'hints_aug', verbose=True)\n",
    "_= ngram_dataset_freq(global_sr['test'], 'hints_aug', verbose=True)\n",
    "\n",
    "_= ngram_dataset_freq(global_sr['train'], 'hints_aug', n=2, verbose=True)\n",
    "_= ngram_dataset_freq(global_sr['test'], 'hints_aug', n=2, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CLEVR-Humans\n",
    "\n",
    "Note: official paper preprocessing is available here. https://github.com/facebookresearch/clevr-iep/blob/master/TRAINING.md\n",
    "\n",
    "Format: JSON files have keys ['info', 'questions']; questions is a list with format:\n",
    "```\n",
    "{u'answer': u'yes', u'question': u'Is there a blue cylinder?', u'split': u'train', u'image_index': 1429, u'image_filename': u'CLEVR_train_001429.png'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17817 questions in train\n",
      "Found 7145 questions in test\n",
      "Found 7202 questions in val\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "def tokenize(s, delim=' ',\n",
    "      add_start_token=True, add_end_token=True,\n",
    "      punct_to_keep=[';', ','], punct_to_remove=['?', '.']):\n",
    "    \"\"\"Taken from Johnson et. al\"\"\"\n",
    "    s = s.lower()\n",
    "    if punct_to_keep is not None:\n",
    "        for p in punct_to_keep:\n",
    "            s = s.replace(p, '%s%s' % (delim, p))\n",
    "    if punct_to_remove is not None:\n",
    "        for p in punct_to_remove:\n",
    "            s = s.replace(p, '')\n",
    "    tokens = s.split(delim)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "paths = [\"./data/clevr_humans/CLEVR-Humans-%s.json\" % split for split in (\"train\", \"test\", \"val\")]\n",
    "\n",
    "clevr_humans = {}\n",
    "for split in ('train', 'test', 'val'):\n",
    "    path = \"./data/clevr_humans/CLEVR-Humans-%s.json\" % split\n",
    "    json_data = open(path).read()\n",
    "    clevr_humans[split] = json.loads(json_data)['questions']\n",
    "    print(\"Found %d questions in %s\" % (len(clevr_humans[split]), split))\n",
    "    # Tokenize\n",
    "    for j, example in enumerate(clevr_humans[split]):\n",
    "        clevr_humans[split][j]['tokenized'] = tokenize(clevr_humans[split][j]['question'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Printing for ngram, n=1\n",
      "Num descriptions: 17817\n",
      "Description avg: 8, med: 8, min: 4, max: 35\n",
      "Vocabulary size: 990\n",
      "Ngrams with freq > 10: 293\n",
      "Total ngram in corpus: 155133\n",
      "50 most common: (not including letters): [((u'the',), 20305), ((u'is',), 9668), ((u'are',), 8744), ((u'what',), 7279), ((u'color',), 5413), ((u'of',), 5090), ((u'how',), 4956), ((u'many',), 4947), ((u'there',), 4497), ((u'objects',), 4180), ((u'object',), 3829), ((u'shape',), 2889), ((u'same',), 2564), ((u'cube',), 2249), ((u'in',), 1970), ((u'cylinder',), 1906), ((u'large',), 1874), ((u'shiny',), 1771), ((u'cubes',), 1680), ((u'small',), 1569), ((u'sphere',), 1563), ((u'that',), 1442), ((u'cylinders',), 1438), ((u'metallic',), 1422), ((u'to',), 1386), ((u'as',), 1278), ((u'red',), 1257), ((u'matte',), 1238), ((u'purple',), 1182), ((u'green',), 1173), ((u'material',), 1169), ((u'blue',), 1159), ((u'any',), 1140), ((u'spheres',), 1128), ((u'and',), 1100), ((u'all',), 1081), ((u'ball',), 1051), ((u'yellow',), 896), ((u'balls',), 862), ((u'two',), 835), ((u'behind',), 821), ((u'more',), 807), ((u'than',), 767), ((u'left',), 718), ((u'right',), 692), ((u'gray',), 687), ((u'rubber',), 662), ((u'not',), 654), ((u'front',), 640), ((u'or',), 596)]\n",
      "Sample descriptions: \n",
      "what color is the small object behind the green cube\n",
      "what color is the shiny round object to the right of the shiny purple ball\n",
      "what is the same of the smallestt object\n",
      "what color is the object in between the silver cube and silver sphere\n",
      "there are two small cubes and small spheres ; are there more metal small spheres or metal small cubes\n",
      "Printing for ngram, n=2\n",
      "Num descriptions: 17817\n",
      "Description avg: 8, med: 8, min: 4, max: 35\n",
      "Vocabulary size: 8161\n",
      "Ngrams with freq > 10: 1330\n",
      "Total ngram in corpus: 137316\n",
      "50 most common: (not including letters): [((u'is', u'the'), 6665), ((u'how', u'many'), 4933), ((u'of', u'the'), 3872), ((u'are', u'there'), 3413), ((u'what', u'color'), 3409), ((u'color', u'is'), 2960), ((u'the', u'same'), 2521), ((u'what', u'is'), 1965), ((u'objects', u'are'), 1677), ((u'are', u'the'), 1294), ((u'the', u'object'), 1245), ((u'the', u'large'), 1186), ((u'what', u'shape'), 1184), ((u'to', u'the'), 1147), ((u'as', u'the'), 1120), ((u'shape', u'is'), 1043), ((u'in', u'the'), 880), ((u'the', u'small'), 835), ((u'that', u'is'), 834), ((u'same', u'color'), 804), ((u'the', u'shape'), 780), ((u'the', u'color'), 772), ((u'many', u'objects'), 768), ((u'color', u'of'), 758), ((u'is', u'there'), 731), ((u'are', u'all'), 714), ((u'behind', u'the'), 694), ((u'there', u'more'), 693), ((u'cubes', u'are'), 645), ((u'shape', u'of'), 636), ((u'all', u'the'), 618), ((u'same', u'material'), 613), ((u'the', u'objects'), 575), ((u'object', u'that'), 561), ((u'cylinders', u'are'), 559), ((u'there', u'any'), 547), ((u'there', u'a'), 522), ((u'the', u'right'), 515), ((u'the', u'left'), 485), ((u'same', u'shape'), 483), ((u'the', u'two'), 464), ((u'the', u'red'), 461), ((u'the', u'largest'), 456), ((u'the', u'green'), 456), ((u'are', u'any'), 453), ((u'same', u'size'), 452), ((u'in', u'front'), 443), ((u'the', u'purple'), 424), ((u'many', u'cubes'), 421), ((u'the', u'blue'), 417)]\n",
      "Sample descriptions: \n",
      "are there any matted objects the same shape as the object that isn't matted\n",
      "what color is the large cube\n",
      "what color is the object farthest back\n",
      "are there two cylinders that are the same\n",
      "how many objects with no sharp edges ",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN\")\n",
    "_= ngram_dataset_freq(clevr_humans['train'], 'tokenized', verbose=True)\n",
    "_= ngram_dataset_freq(clevr_humans['train'], 'tokenized', n=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Domain Frequency Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Reasoning (Janner) and CLEVR-Humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Reasoning Local and CLEVR-Humans\n",
      "Cross dataset frequency for 2 datasets.\n",
      "Original vocabulary sizes are [196, 990]\n",
      "Combined vocabulary size is 1069; intersected vocab is: 117\n",
      "Intersection ngrams with freq > 10: 89\n",
      "50 most common: (not including letters): [((u'the',), 22085), ((u'is',), 9786), ((u'are',), 8745), ((u'of',), 5785), ((u'object',), 3830), ((u'same',), 2565), ((u'to',), 2070), ((u'in',), 1995), ((u'that',), 1555), ((u'and',), 1540), ((u'a',), 1437), ((u'red',), 1270), ((u'blue',), 1229), ((u'purple',), 1216), ((u'green',), 1207), ((u'left',), 1168), ((u'two',), 1065), ((u'right',), 1042), ((u'yellow',), 910), ((u'one',), 780), ((u',',), 639), ((u'brown',), 470), ((u'on',), 456), ((u'other',), 456), ((u'most',), 396), ((u'square',), 395), ((u'above',), 390), ((u'from',), 375), ((u'which',), 344), ((u'between',), 339), ((u'with',), 293), ((u'next',), 276), ((u'by',), 274), ((u'closest',), 269), ((u'circle',), 255), ((u'it',), 251), ((u'diamond',), 230), ((u'gold',), 223), ((u'triangle',), 194), ((u'has',), 181), ((u'block',), 176), ((u'three',), 175), ((u'space',), 164), ((u'squares',), 151), ((u'far',), 139), ((u'blocks',), 135), ((u'but',), 132), ((u'you',), 131), ((u'directly',), 126), ((u'round',), 117)]\n",
      "Cross dataset frequency for 2 datasets.\n",
      "Original vocabulary sizes are [1148, 8161]\n",
      "Combined vocabulary size is 9130; intersected vocab is: 179\n",
      "Intersection ngrams with freq > 10: 106\n",
      "50 most common: (not including letters): [((u'of', u'the'), 4217), ((u'to', u'the'), 1690), ((u'that', u'is'), 938), ((u'in', u'the'), 891), ((u'the', u'left'), 712), ((u'left', u'of'), 702), ((u'the', u'right'), 699), ((u'right', u'of'), 595), ((u'the', u'green'), 469), ((u'the', u'two'), 468), ((u'the', u'red'), 467), ((u'the', u'blue'), 445), ((u'the', u'purple'), 431), ((u'on', u'the'), 369), ((u'the', u'yellow'), 329), ((u'next', u'to'), 270), ((u'from', u'the'), 269), ((u'the', u'brown'), 207), ((u'between', u'the'), 198), ((u'closest', u'to'), 195), ((u'is', u'in'), 169), ((u'and', u'the'), 164), ((u'the', u'other'), 161), ((u'is', u'a'), 159), ((u'and', u'one'), 150), ((u'above', u'the'), 147), ((u'with', u'the'), 138), ((u'the', u'far'), 129), ((u'is', u'to'), 109), ((u'the', u'middle'), 98), ((u'that', u'has'), 88), ((u'and', u'to'), 86), ((u'a', u'green'), 85), ((u'the', u'gold'), 83), ((u'a', u'blue'), 82), ((u'has', u'the'), 82), ((u'the', u'circle'), 80), ((u'a', u'purple'), 72), ((u'the', u'square'), 68), ((u'is', u'one'), 66), ((u'of', u'a'), 64), ((u'is', u'closest'), 59), ((u'between', u'two'), 58), ((u'in', u'between'), 57), ((u'and', u'two'), 57), ((u'one', u'to'), 54), ((u'is', u'between'), 53), ((u',', u'and'), 52), ((u'the', u'leftmost'), 49), ((u'which', u'is'), 47)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Spatial Reasoning Local and CLEVR-Humans\")\n",
    "local_sr_fdist = ngram_dataset_freq(local_sr['train'], 'hints_aug', verbose=False)\n",
    "clevr_fdist = ngram_dataset_freq(clevr_humans['train'], 'tokenized', verbose=False)\n",
    "_ = ngram_cross_dataset_freq([local_sr_fdist, clevr_fdist], verbose=True)\n",
    "\n",
    "local_sr_fdist = ngram_dataset_freq(local_sr['train'], 'hints_aug', n=2, verbose=False)\n",
    "clevr_fdist = ngram_dataset_freq(clevr_humans['train'], 'tokenized', n=2, verbose=False)\n",
    "_ = ngram_cross_dataset_freq([local_sr_fdist, clevr_fdist], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Reasoning Global and CLEVR-Humans\n",
      "Cross dataset frequency for 2 datasets.\n",
      "Original vocabulary sizes are [191, 990]\n",
      "Combined vocabulary size is 1079; intersected vocab is: 102\n",
      "Intersection ngrams with freq > 10: 81\n",
      "50 most common: (not including letters): [((u'the',), 21904), ((u'is',), 9719), ((u'of',), 5509), ((u'object',), 3833), ((u'same',), 2565), ((u'to',), 2187), ((u'in',), 1984), ((u'that',), 1478), ((u'a',), 1411), ((u'as',), 1279), ((u'red',), 1259), ((u'and',), 1123), ((u'all',), 1082), ((u'left',), 969), ((u'right',), 881), ((u'two',), 873), ((u'most',), 667), ((u',',), 614), ((u'or',), 597), ((u'items',), 591), ((u'one',), 532), ((u'on',), 460), ((u'other',), 458), ((u'go',), 426), ((u'square',), 408), ((u'which',), 344), ((u'farthest',), 324), ((u'only',), 311), ((u'from',), 293), ((u'between',), 266), ((u'closest',), 266), ((u'next',), 255), ((u'it',), 245), ((u'move',), 228), ((u'both',), 214), ((u'above',), 196), ((u'with',), 189), ((u'furthest',), 184), ((u'block',), 184), ((u'has',), 180), ((u'three',), 159), ((u'if',), 156), ((u'topmost',), 145), ((u'squares',), 133), ((u'bottom',), 132), ((u'directly',), 131), ((u'blocks',), 129), ((u'top',), 121), ((u'middle',), 109), ((u'another',), 101)]\n",
      "Cross dataset frequency for 2 datasets.\n",
      "Original vocabulary sizes are [844, 8161]\n",
      "Combined vocabulary size is 8836; intersected vocab is: 169\n",
      "Intersection ngrams with freq > 10: 104\n",
      "50 most common: (not including letters): [((u'is', u'the'), 6668), ((u'of', u'the'), 4230), ((u'the', u'same'), 2522), ((u'to', u'the'), 1835), ((u'the', u'object'), 1249), ((u'as', u'the'), 1121), ((u'in', u'the'), 892), ((u'that', u'is'), 863), ((u'the', u'left'), 646), ((u'the', u'right'), 642), ((u'all', u'the'), 619), ((u'left', u'of'), 516), ((u'the', u'two'), 469), ((u'the', u'red'), 463), ((u'right', u'of'), 462), ((u'on', u'the'), 376), ((u'the', u'only'), 259), ((u'next', u'to'), 251), ((u'the', u'most'), 250), ((u'from', u'the'), 227), ((u'closest', u'to'), 192), ((u'object', u'to'), 181), ((u'between', u'the'), 181), ((u'is', u'in'), 171), ((u'the', u'other'), 161), ((u'above', u'the'), 153), ((u'and', u'the'), 152), ((u'the', u'topmost'), 131), ((u'object', u'on'), 126), ((u'is', u'farthest'), 115), ((u'the', u'farthest'), 114), ((u'the', u'square'), 114), ((u'with', u'the'), 113), ((u'the', u'middle'), 105), ((u'the', u'bottom'), 100), ((u'is', u'to'), 97), ((u'that', u'has'), 88), ((u'farthest', u'left'), 87), ((u'if', u'the'), 85), ((u'the', u'top'), 85), ((u'the', u'leftmost'), 81), ((u'the', u'rightmost'), 71), ((u'one', u'square'), 69), ((u'the', u'furthest'), 64), ((u'each', u'other'), 61), ((u'furthest', u'to'), 61), ((u'of', u'a'), 58), ((u'square', u'to'), 56), ((u'between', u'two'), 54), ((u'bottom', u'most'), 50)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Spatial Reasoning Global and CLEVR-Humans\")\n",
    "global_sr_fdist = ngram_dataset_freq(global_sr['train'], 'hints_aug', verbose=False)\n",
    "clevr_fdist = ngram_dataset_freq(clevr_humans['train'], 'tokenized', verbose=False)\n",
    "_ = ngram_cross_dataset_freq([global_sr_fdist, clevr_fdist], verbose=True)\n",
    "\n",
    "global_sr_fdist = ngram_dataset_freq(global_sr['train'], 'hints_aug', n=2, verbose=False)\n",
    "clevr_fdist = ngram_dataset_freq(clevr_humans['train'], 'tokenized', n=2, verbose=False)\n",
    "_ = ngram_cross_dataset_freq([global_sr_fdist, clevr_fdist], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
